<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Startup Lab - rationality</title><link href="/" rel="alternate"></link><link href="/feeds/rationality.atom.xml" rel="self"></link><id>/</id><updated>2017-09-17T00:00:00-07:00</updated><entry><title>Expected Utility</title><link href="/post/expected-utility" rel="alternate"></link><published>2017-09-17T00:00:00-07:00</published><updated>2017-09-17T00:00:00-07:00</updated><author><name>Ray Alez</name></author><id>tag:None,2017-09-17:/post/expected-utility</id><summary type="html">&lt;p&gt;Imagine I offer you a gamble. I will spin the wheel that looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1520/1*hJtobFtiK-N_SM0isn0HWg.png"&gt;&lt;/p&gt;
&lt;p&gt;And you win the amount of money that it will choose. If it hits a negative number you owe me that much. Should you play or not?&lt;/p&gt;
</summary><content type="html">&lt;p&gt;Imagine I offer you a gamble. I will spin the wheel that looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1520/1*hJtobFtiK-N_SM0isn0HWg.png"&gt;&lt;/p&gt;
&lt;p&gt;And you win the amount of money that it will choose. If it hits a negative number you owe me that much. Should you play or not?&lt;/p&gt;


&lt;p&gt;This is the kind of problem you are solving every time you are trying to decide whether or not to take any risky action.&lt;/p&gt;
&lt;p&gt;It comes down to figuring out whether the action has a positive or negative value to you, so called Expected Utility, whether it’s benefits outweigh the potential risks.&lt;/p&gt;
&lt;p&gt;To find out the answer, you need to know the sum of all the potential benefits multiplied by their probability, and compare it to the benefits and probability of the risks.&lt;/p&gt;
&lt;p&gt;So first we estimate probabilities of each outcome:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1520/1*ubAzVyTA-iWcX-FkG1gDag.png"&gt;&lt;/p&gt;
&lt;p&gt;And then we calculate our upside:&lt;/p&gt;
&lt;p&gt;&amp;gt; $20 * 0.3 + $15 * 0.2 + $5 * 0.2 = $10&lt;/p&gt;
&lt;p&gt;And the downside:&lt;/p&gt;
&lt;p&gt;&amp;gt; -$10 * 0.2 - $30 * 0.1 = -$5&lt;/p&gt;
&lt;p&gt;So now we can see that the expected utility of playing this game is&lt;/p&gt;
&lt;p&gt;&amp;gt; $10 - $5 = $5&lt;/p&gt;
&lt;p&gt;So now we know that if you play this game many times, on average, you will be making $5 every game, so that’s a good deal.&lt;/p&gt;
&lt;p&gt;This is a very useful concept, because when you think like that about every action you take, you end up making much better decisions. You don’t take dumb risks, and you don’t miss great opportunities.&lt;/p&gt;
&lt;p&gt;In life, we need to make decisions under uncertainty. When you know your values, and take actions with maximum expected utility, you can take the optimal way towards achieving your goals.&lt;/p&gt;</content></entry><entry><title>Anchoring Bias</title><link href="/post/anchoring-bias" rel="alternate"></link><published>2016-07-23T00:00:00-07:00</published><updated>2016-07-23T00:00:00-07:00</updated><author><name>Ray Alez</name></author><id>tag:None,2016-07-23:/post/anchoring-bias</id><summary type="html">&lt;p&gt;People rely too heavily on the piece of information that they have received first.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/2560/1*OzzD7O4yEUaCadcM4XBrsw.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;Let’s say I spin a wheel, with numbers ranging from 1 to 100. Then I ask you to guess a number of countries in Africa. Turns out, statistically, your answer will be much lower if the wheel has showed number 16 than if the wheel would have showed 87. Why would that happen? The number is clearly random and has nothing to do with the correct answer.&lt;/p&gt;
&lt;p&gt;Turns out, even when presented with the clearly false information, your mind will use it as an “anchor” — a starting point you will use to make a guess. Then you then “slide” up or down from that anchor, until the result seems reasonable.&lt;/p&gt;
&lt;p&gt;People rely too heavily on the piece of information that they have received first. They use it to form the initial guess, and then make incremental adjustments based on additional information, but that is usually not enough, and the initial random anchor keeps a lot of influence over future decisions.&lt;/p&gt;
&lt;p&gt;Often that leads to mistakes, and people who know about it can use it to their advantage. For example when you’re buying a house, the salesman will first take you to the expensive house he does not expect you to buy, so that the next offer he shows you would seem mich more reasonable, even if it’s still overpriced.&lt;/p&gt;
&lt;p&gt;To get rid of this bias, the first step is to be aware of it, try to observe your thinking, and notice when instead of coming up with an independent guess, you are making adjustment from some initial anchor. Then — think about the anchor in the opposite direction. If the initial number was too large you want to think about the one thats too small, and vice versa. That should help you to come up with a more accurate estimate.&lt;/p&gt;</content></entry><entry><title>False Dichotomy</title><link href="/post/false-dichotomy" rel="alternate"></link><published>2016-06-04T00:00:00-07:00</published><updated>2016-06-04T00:00:00-07:00</updated><author><name>Ray Alez</name></author><id>tag:None,2016-06-04:/post/false-dichotomy</id><summary type="html">&lt;p&gt;Taking a complex issue and boiling it down to 2 options when there’s more alternatives available.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/3200/1*aIbynppEMamCrQSqQx6enQ.jpeg"&gt;&lt;/p&gt;
&lt;p&gt;False Dichotomy means taking a complex issue, and boiling it down to 2 simple mutually exclusive choices, when in reality there’s more alternatives available. To make their side look more appealing, people present nuanced arguments as black and white, or take extremes and pretend like they are the only options.&lt;/p&gt;
&lt;p&gt;This kind of thinking often leads to ignoring potential solutions, and prevents us from gaining an accurate understanding of the situation.&lt;/p&gt;
&lt;p&gt;It also leads to polarization of opinions — people treat an argument as a battle against the opposite side, and as a result take more and more extreme positions. Sometimes people are afraid to offer measured opinions because their own side will call them a traitor.&lt;/p&gt;
&lt;p&gt;For example a politician may demonize drugs and suggest longer sentences for drug addicts, because taking a more balanced view will make him look like he supports drugs.&lt;/p&gt;
&lt;p&gt;Some other examples of this fallacy are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Either you are with us or against us.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Either we improve this law or everyone will suffer.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Either you go to church or you are a bad person.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Either you are a republican or a democrat.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To overcome it, remember that in reality things are rarely one-sided. Most of the time complex issues have costs and benefits. Optimizing for values often requires trade offs. To get the most accurate picture, you want to see flaws and advantages of both positions.&lt;/p&gt;
&lt;p&gt;Just because you support one side of the with one group of people, doesn’t mean you have to automatically agree with everything that side says and reject the opposite side.&lt;/p&gt;</content></entry><entry><title>Rationalization</title><link href="/post/rationalization" rel="alternate"></link><published>2016-04-03T00:07:00-07:00</published><updated>2016-04-03T00:07:00-07:00</updated><author><name>Ray Alez</name></author><id>tag:None,2016-04-03:/post/rationalization</id><summary type="html">&lt;p&gt;We do whatever feels good, and then come up with explanations that make us feel better about it.&lt;/p&gt;</summary><content type="html">&lt;p&gt;You see this beautiful girl standing across the room. You would like to approach her and start a conversation, but then you think to yourself “Nah, she probably has a boyfriend. Also she wouldn’t like me anyway. Not to mention that I need to focus on studying, I don’t really have time for relationships.” So you look away, go home, play World of Warcraft, eat a pizza, feed your cats, hump your human-sized action figure of Chewbacca, go to sleep, and die alone.&lt;/p&gt;
&lt;p&gt;Were your excuses the &lt;strong&gt;actual&lt;/strong&gt; reasons for not approaching? Imagine if you’d know with 100% certainty that you will not get rejected, would you still decide that you’d rather focus on studying?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rationalization&lt;/strong&gt; means coming up with seemingly logical/rational explanations for irrational behavior. We do whatever feels good, or whatever is easy/convenient/profitable, and then come up with explanations that make us feel better about our decisions.&lt;/p&gt;
&lt;p&gt;Imagine you want to buy a new car. You don’t know much about the recent models, so you research, select a few options, look at their specs, make the list of pros and cons of each one. At the bottom the list, you finally write down your decison.&lt;/p&gt;
&lt;p&gt;Now let’s say you’re a salesman, and your job is to sell a certain model. You take a sheet of paper, and at the bottom you write “and that’s is why this is the best car ever”. Then you do your research, compare options, and above the bottom line, you write a list of reasons why that’s the best model.&lt;/p&gt;
&lt;p&gt;You are not lying, all the reasons are true, but you started thinking about them after the choice has already been determined. Your answer was already either true or false before you came up with explanations, and they &lt;em&gt;could not change your choice&lt;/em&gt;. Your &lt;strong&gt;actual&lt;/strong&gt;reason for making it was “that’s my job to sell this car”.&lt;/p&gt;
&lt;p&gt;It is impossible to make a choice or belief rational even by using the smartest, most convincing arguments. The purpose of rationality is not to argue convincingly for a position, but to decide which position to argue for. Once your position is fixed, it can not become more rational. Rationality takes evidence and knowledge and looks for the best, most accurate conclusions. Rationalization runs in reverse, it starts with the conclusion and searches for reasons. If you already know your answer — thinking about it doesn’t matter.&lt;/p&gt;
&lt;p&gt;Your success is determined by how good your decisions are, and when you are rationalizing, the actual algorithm you are using to make decisions is “whatever feels good”.&lt;/p&gt;
&lt;p&gt;So how do you defeat rationalization? First of all, it comes down to being aware of it, and being honest with yourself. Always ask — what are the &lt;strong&gt;actual&lt;/strong&gt; reasons for my beliefs/decisions/actions?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Are you eating this ice cream because “well, it has nuts in it, so it’s actually kinda healthy” or because it tastes good?&lt;/li&gt;
&lt;li&gt;Are you playing this computer game because “life is to be enjoyed”, and this game actually brings you joy? It is the best thing you want to do with your life right now, or just the easiest?&lt;/li&gt;
&lt;li&gt;Do you skip gym this time because it’s the best day to take a break and let your body rest and restore, or because it’s raining outside?&lt;/li&gt;
&lt;li&gt;Now that you didn’t get that job, it doesn’t seem that great, is it because didn’t actually want it anyway?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And be suspicious when your explanations conveniently happen to give you the permission to do the thing you wanted to do before coming up with them, or make you feel better about doing/believing things that you like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Do keep your religion because it’s a “good moral guidance”, because it makes sense, or because your parents believed in it?&lt;/li&gt;
&lt;li&gt;Are you defending piracy because “it actually helps companies to promote their content, so it’s not a big deal, also information should be free”, or because it’s really convenient to watch a free movie?&lt;/li&gt;
&lt;li&gt;Is your city or country actually the best place in the world, or do you like it because you were born here?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Also notice that when you are looking for answers that you don’t already know, you feel curious, you are craving to know the answer, yet rationalization usually makes you more confident/comfortable/justified.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/images/rationality/rationalization/rationalization.png"&gt;&lt;/p&gt;</content></entry><entry><title>Sunk Cost Fallacy</title><link href="/post/sunk-cost-fallacy" rel="alternate"></link><published>2016-04-03T00:05:00-07:00</published><updated>2016-04-03T00:05:00-07:00</updated><author><name>Ray Alez</name></author><id>tag:None,2016-04-03:/post/sunk-cost-fallacy</id><summary type="html">&lt;p&gt;Let’s say you’ve been planning to go see a movie this Friday, and have already bought a ticket, but now that it’s time to go out you realize that you don’t want to go, and that you would rather enjoy spending your evening at home. Should you go or not?&lt;/p&gt;</summary><content type="html">&lt;p&gt;Let’s say you’ve been planning to go see a movie this Friday, and have already bought a ticket, but now that it’s time to go out you realize that you don’t want to go, and that you would rather enjoy spending your evening at home. Should you go or not?&lt;/p&gt;
&lt;p&gt;Most of the people say yes, after all, the ticket has already been paid for, and it’s nonrefundable, so you wouldn’t want it to be wasted, right?&lt;/p&gt;
&lt;p&gt;That is called a Sunk Cost Fallacy — the ​idea that people tend to stick with the courses of action they have ​invested ​money, ​time, or ​effort in, ​even when continuing is not the best thing to do.&lt;/p&gt;
&lt;p&gt;If you think about it, it’s irrational to let the costs that we can’t recover to influence our decisions, only future costs and benefits should matter. But we don’t want to admit our mistakes, to “waste” our investment, so we often stick by our past choices that continue costing us more.&lt;/p&gt;
&lt;p&gt;The movie example may not make it seem like a big deal, but this fallacy often leads to more significant consequences. Many people stick with professions they dislike because they have spent that all this money and time on getting their degree. They often don’t consider that starting over is better than being miserable for the rest of your career. Or people stay in unhappy relationships because of all the time they have invested in them.&lt;/p&gt;
&lt;p&gt;To overcome this fallacy — be aware of it, ask yourself where do I fall victim to it. Learn to recognize it, and once you do —admit that it’s irrational.&lt;/p&gt;
&lt;p&gt;People often commit this fallacy not because they think it’s logical, but because they are emotionally invested in the effort they put in, so you need to understand that sometimes it’s better to let go. Imagine that you’ve just been dropped into your current life situation with no warning, and do what is in your best interest.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you have realized half way through reading a book that it’s not useful or interesting — give it up.&lt;/li&gt;
&lt;li&gt;Are you trying to finish eating this sandwich because it’s already been paid for, even though you’re not hungry? Throw it away, it doesn’t benefit anybody.&lt;/li&gt;
&lt;li&gt;Do you keep going to a bad/useless class that you’ve paid a lot of money for? You probably don’t need to.&lt;/li&gt;
&lt;li&gt;Did you put so much sweat in writing this scene in your screenplay, only to realize that it doesn’t make the movie better? Cut it out.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By the way, I don’t mean to say that you should be wasteful, it’s always wise to try anticipating such things in advance and to avoid doing them in the first place. But once you did, don’t spend even more energy on it, realize that putting more time into it wont make it more worth it, cut your losses, and move on.&lt;/p&gt;
&lt;p&gt;You can’t get your money, energy and time back, but you can still make yourself happier.&lt;/p&gt;</content></entry><entry><title>Confirmation Bias</title><link href="/post/confirmation-bias" rel="alternate"></link><published>2016-04-03T00:04:00-07:00</published><updated>2016-04-03T00:04:00-07:00</updated><author><name>Ray Alez</name></author><id>tag:None,2016-04-03:/post/confirmation-bias</id><summary type="html">&lt;p&gt;We jump to conclusions, and then look for information that confirms our beliefs.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Let’s say your elbow is itchy, and you are starting to fear that it might be serious. You type in google “itchy elbow, serious symptom”, and in 20 minutes you are convinced that you have elbow cancer, space AIDS, and a severe case of acute ladidadidosis. The more you search, the more certain you are of your impending doom.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/images/rationality/confirmation-bias/confirmation-bias-1.png"&gt;&lt;/p&gt;
&lt;p&gt;In a similar fashion, you may type “dolphins are racist”, and find out all about dolphins being the secret force behind holocaust.&lt;/p&gt;
&lt;p&gt;You can easily find a confirmation for any belief, and people often do.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We tend to look for information that confirms our beliefs.&lt;/strong&gt; We jump to conclusions, assume that our initial guess is correct, and then look for evidence that supports it.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/images/rationality/confirmation-bias/confirmation-bias-2.png"&gt;&lt;/p&gt;
&lt;p&gt;That is called &lt;strong&gt;confirmation bias&lt;/strong&gt;, and it has many effects that prevent us from being more intelligent and developing accurate beliefs.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/images/rationality/confirmation-bias/confirmation-bias-3.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We set higher standards for evidence that disagrees with our ideas.&lt;/strong&gt; For example, if you don’t believe in evolution, you may say that this is because there’s a gap in the fossils between monkeys and humans, and so there’s not enough evidence to prove that evolution is true. At the same time, you may have no problem taking an old book and the words of a priest as a convncing support for your beliefs.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;When information is ambiguous, we tend to interpret it as supporting our existing position.&lt;/strong&gt; Lets say someone was rude to you the first time youve met, then the next time he does something nice, you may think that he’s just being manipulative or wants something from you, so you become even more convinced that this is a bad person. On the other hand if the first time you’ve met someone he was nice, and is now he’s acting like a jerk, you may just assume that he’s simply having a bad day.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Also, we remember things selectively — facts that prove us right are easier to recall.&lt;/strong&gt; People who believe in horoscopes, probably do that because they can easily remember all the times horoscopes were right, and forget or ignore countless times they were wrong.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/images/rationality/confirmation-bias/confirmation-bias-4.png"&gt;&lt;/p&gt;
&lt;p&gt;To overcome confirmation bias, try to balance the sources you get your information from, to look at the both sides of the argument, think about what kind of evidence would disprove your theory, and actively search for things that challenge your beliefs.&lt;/p&gt;</content></entry><entry><title>What are Cognitive Biases?</title><link href="/post/what-are-cognitive-biases" rel="alternate"></link><published>2016-04-03T00:03:00-07:00</published><updated>2016-04-03T00:03:00-07:00</updated><author><name>Ray Alez</name></author><id>tag:None,2016-04-03:/post/what-are-cognitive-biases</id><summary type="html">&lt;p&gt;Our brain takes mental shortcuts that distort our picture of the world.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="" src="/images/rationality/biases/biases-1.png"&gt;
Imagine you have a basket of fruits(apples and oranges), you reach out, take one at random, and eat it. Then you decide you’re hungry, and eat a few more. At that point you realize that you ate like 5 apples and only one orange, so you think that there’s way more apples in there. Makes sense.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/images/rationality/biases/biases-2.png"&gt;
Now you reach into a different basket, and grab a bunch of berries —5 strawberries and 10 blueberries. Should you think that there’s 2 times more blueberries here? Not really, because strawberries are bigger and heavier, so there’s more of them at the bottom of the basket than at the top, and your estimate would be biased.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/images/rationality/biases/biases-3.png"&gt;&lt;/p&gt;
&lt;p&gt;This is called statistical bias. When your information is skewed, you form an inaccurate picture of the world. You could try to gather more data, but it wouldn’t help, because the way you gather it is fundamentally flawed.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/images/rationality/biases/biases-4.png"&gt;&lt;/p&gt;
&lt;p&gt;But now imagine you reach into the third basket, and holy shit! — it’s dollar bills! You’re rich, you’ll finally be able to buy your own giraffe, you always wanted one.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/images/rationality/biases/biases-5.png"&gt;&lt;/p&gt;
&lt;p&gt;Then you notice that some of the bills are $100, and other’s are only $5. But you think most of bills in the bag are probably $100, right? I mean you really wish they were, after all, giraffes are expensive, and you don’t want to settle for buying some lame capybara at this point.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/images/rationality/biases/biases-6.png"&gt;&lt;/p&gt;
&lt;p&gt;In this case your expectation is incorrect not because you have wrong information, but because it’s influenced by a different kind of bias — a cognitive bias.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/images/rationality/biases/biases-7.png"&gt;&lt;/p&gt;
&lt;p&gt;Because our brain does not have the time and energy to accurately process all the information it perceives, it takes mental shortcuts(called heuristics). Most of the time they are useful, but often they mislead us and result in systematic errors in our thinking — that is what cognitive biases are.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/images/rationality/biases/biases-8.png"&gt;&lt;/p&gt;
&lt;p&gt;Just like statistical biases, cognitive biases distort your picture of the world, and when your method of learning about the world is flawed, gathering more information will not help to correct the error, in fact it can even worsen it.&lt;/p&gt;
&lt;p&gt;These biases prevent us from having accurate beliefs, making good decisions, and achieving our goals. Sometimes they result in small mistakes(like losing some money by playing a lottery), sometimes mistakes are not so small(burning witches, holocaust, me watching Star Wars prequels).&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/images/rationality/biases/biases-9.png"&gt;&lt;/p&gt;
&lt;p&gt;Cognitive biases are not a result of being an unfair or a dishonest person, they are not committed by choice, they are a fundamental property of how humans think, they are flaws in the lens through which we look at the world. Being biased is like having a miscalibrated measuring instrument, except in this case the instrument is your brain.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="/images/rationality/biases/biases-10.png"&gt;&lt;/p&gt;
&lt;p&gt;So how do we fix it? Instead of relying on our natural hunches and intuitions, we can learn to recognize our mistakes, and then use superior tools(rationality and logic) to correct them.&lt;/p&gt;
&lt;p&gt;A good place to start is to learn about the types of biases, fallacies, and the cognitive tools we can use to prevent them, which is what this series of posts is about.&lt;/p&gt;</content></entry></feed>